## 使用SFT改进中小规模结构化数据的咨询
## 背景介绍
在日常生活中，有许多场景是需要根据已有的结构化的信息、例如Excel/CSV 表格、MySQL数据库和HTML Table等进行咨询和问询，现在企业将LLM融入自身业务中的一个落脚点是希望LLM能在这样的场景中替代人工查询或者复杂的网页填表和选择框，直接通过对话的方式进行语义检索。目前对于这种任务的处理主要使用的商业落地方案集中于使用基于Text-Embedding的RAG(Retrieval-augmented generation, RAG)，但RAG方案在大规模数据和策略设计得当的情况下表现尚可，在中小规模数据中的表现不尽人意，最近自己尝试采用了SFT的方案来解决这个问题，感觉获得了一些比RAG方案更好的结果，将解决思路分享，希望可以启发思考共同进步。
## RAG
RAG技术的基本原理是基于text-embedding的retrival和rerank，它的前身其实是NLP任务中的文本分类任务和聚类、排序等场景下基于text-embedding进行语义检索的一种分支方法，最先开始应用其实并不是在大模型出现之后，早年电商的检索业务：1）图像/视频/多模态检索；2）智能问答；3）推荐/广告等其实都是基于它。Milvus / Qdrant / Chroma 等支持向量索引类型的数据库核心也是实现一个高效的新的语义检索的字段，让用户可以高效的通过类似传统关系型数据库中的一个字段一样，去建立一个与传统基于字符串的 **模糊匹配/正则匹配/规则查找** 方式所不同的**基于Embedding的语义查找**字段。听上去是挺不错的，RAG方案在数据规模充足（上亿）的情况下体现出了不错的粗看效果，Milvus的官网中展示的合作伙伴包括一些著名的大厂，例如 Nvidia / Ebay / Shopee / Line 等，这些大厂并不缺语料来源，但在中小规模（低于1w）的量级下，我自总结了RAG体现出的两大主要缺点：

1. Retrival阶段的准确性十分依赖用户 Query 对于 向量型数据库中的 Corpus 字段的命中率 
2. 十分依赖RAG策略设计 / 语料切分策略 / RAG基于的text-embedding模型的质量

最近Arxiv中也有文章总结了对应 [RAG的七宗罪](https://arxiv.org/abs/2401.05856)，知乎 @西红柿牛腩 也对应的写了一篇文章  [RAG系统的“七宗罪”--一周出demo，半年用不好](https://zhuanlan.zhihu.com/p/677691070)，有兴趣可以详细参考。分析一下为什么在大厂的情况下，这两点为什么并不会成为主要阻碍。在大厂的情况中，数据的丰富度远高于普通的小规模表格内容咨询，一个比较典型的案例是Apple官方对于产品的描述和基础功能的使用文档，官方对于功能文档本身维护相对较好，足够详细且足够多，使得用户Query对于Corpus之间的命中率无形之中就高了起来，它们本身就是很好的RAG语料，不需要复杂的策略设计，直接通过一个支持长上下文的Embedding模型就能实现一个能看的BaseLine结果。另一方面，有部分的Apple用户在进行Query时，本身对于产品是有一定的了解的，例如一个用户问: "**Siri**应该如何设置 **捷径**"，在这个问题里，用户至少知道了Apple的产品中包含**Siri** 这个语音助手和 **捷径** 这个功能，但是只是不知道具体的设置步骤或者方法，但实际上这两条信息已经可以通过Text-Embedding的方式对Corpus语料实现较高的命中率了；并且用户在使用iPhone或者Apple的其他产品时，会在长时间的使用过程中积累这些辅助RAG的对应信息。

而在中小型企业内部，例如，我们需要实现的是对于一张大的Excel表格，针对两万行该企业对应服务或微服务的对应描述，这两点；

![alt text](image.png)
## Why SFT
